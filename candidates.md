# Candidate LVAs for the Honors Program

All of them are held in the TU Vienna.

Currently, no internships or similar are included.
I am worried that it's a bit late to seek some internships opportunities?

## Winter-semester 2024

| ECTS  | Title                                                                         |
| ----- | ----------------------------------------------------------------------------- |
| $3$   | [AI/ML in the Era of Climate Change](#aiml-in-the-era-of-climate-change) $^*$ |
| $6$   | [Probabilistic Programming and AI](#probabilistic-programming-and-ai)         |
| $4.5$ | [Selbstorganisierende Systeme](#selbstorganisierende-systeme)                 |
| $6$   | [Logik für Wissensrepräsentation](#logik-für-wissensrepräsentation)           |
| $6$   | [Einführung in Machine Learning](#einführung-in-machine-learning)             |

With an ECTS sum of $25.5$.

## Summer-semester 2025

| ECTS | Title                                                                                                                                                                       |
| ---- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| $3$  | [Sicherheit, Privacy und Erklärbarkeit in Maschinellem Lernen](#sicherheit-privacy-und-erkl%C3%A4rbarkeit-in-maschinellem-lernen)                                           |
| $6$  | [Project in Computer Science 1 - Machine Learning Algorithms und Applications](#project-in-computer-science-1---machine-learning-algorithms-and-applications) $^*$ $^+$     |
| $6$  | [Deep Learning for Natural Language Processing](#deep-learning-for-natural-language-processing) $^*$                                                                        |
| $3$  | [Seminar in Artificial Intelligence: Neuroscience-based Artificial Intelligence](#seminar-in-artificial-intelligence--neuroscience-based-artificial-intelligence) $^*$ $^+$ |
| $3$  | [Knowledge Graphs](#knowledge-graphs) $^*$                                                                                                                                  |

With an ECTS sum of $21$, meaning the whole Honors program would have $46.5$ ECTS points.

---

[ $^*$ ] Those are "new", in the sense that they were not proposed/discussed in [summary](./summary.md) / our previous discussion. They were included to (i) include some non-technical subjects, (ii) for some practical experience, and (iii) because most subjects previously discussed were only available in winter-semesters.  
[ $^+$ ] I don't know if this will be available in 2025, but maybe a similar one will? Especially the project, it was canceled the last two semesters, with the last one being 2023 winter-semester.

## Details

#### AI/ML in the Era of Climate Change

| Name                               | Typ | ECTS | Stunden | Semester | ID      |
| ---------------------------------- | --- | ---- | ------- | -------- | ------- |
| AI/ML in the Era of Climate Change | VU  | 4    | 3       | 2023W    | 194.125 |

[TISS ↗](https://tiss.tuwien.ac.at/course/courseDetails.xhtml?dswid=8472&dsrid=864&courseNr=194125)

##### Lernergebnisse

> Nach positiver Absolvierung der Lehrveranstaltung sind Studierende in der Lage (Beschreibung in Englisch):
>
> This course focuses on two aspects: (1) Sustainable AI (2) AI for Sustainablity.
>
> (1) Sustainable AI: Impact on sustainability by AI models
>
> - Introduction: Hardware advancements, data explosion, and its energy impacts
> - Energy Challenge of AI models: Cost of Training and Inference
> - Large Language Models and their energy consumption
> - A path forward: Methods to address energy consumption of AI models
>
> Goal:
>
> - Understand, apply, and engineer large-scale geographically distributed ML/AL applications
> - Understand resource efficient mechanisms for ML/AL applications with strict latency and/or data quality constraints
> - Understand Geographically distributed inference and learning in Ai/ML
>
> (2) AI for sustainability: Using AI to combat the climate change issues
>
> - AI-driven Smart ICT management (data centre optimizations, chip architecture)
> - AI-driven renewable energy and grid energy management
> - AI for climate change modelling use cases
>
> Goal:
>
> - Understand the common AI/ML applications used for combating climate change (e.g., sensing of water pollution, flood sensing, etc.)
> - Facilitate computation and communication in rural and uninhabited areas
> - Understand how to apply different ML/AI methods for the implementation of applications combating climate change

##### Inhalt der Lehrveranstaltung

> The theoretical concepts are presented and discussed on the basis of slides and scientific literature. Practical tasks are carried out in the laboratory on the basis of these concepts. There will be two practical projects

#### Probabilistic Programming and AI

| Name                             | Typ | ECTS | Stunden | Semester | ID      |
| -------------------------------- | --- | ---- | ------- | -------- | ------- |
| Probabilistic Programming and AI | VU  | 6    | 4       | 2023W    | 194.150 |

[TISS ↗](https://tiss.tuwien.ac.at/course/courseDetails.xhtml?dswid=8472&dsrid=976&courseNr=194150&semester=2023W)

##### Lernergebnisse

> Nach positiver Absolvierung der Lehrveranstaltung sind Studierende in der Lage...
>
> - Understand the basics of generative, probabilistic (Bayesian) modeling and inference
> - Construct probabilistic models via an expressive probabilistic programming language
> - Explain how general purpose programming languages can be extended to support probabilistic constructs
> - Understand standard inference algorithms and their implementations in probabilistic programming languages (MCMC, Variational Inference, etc.)
> - Independently read literature in the probabilistic programming space

##### Inhalt der Lehrveranstaltung

> Probabilistic programming is a general framework to express probabilistic models as programs. It lies at the intersection of machine learning, statistics, and programming languages. While it has classically been seen as mechanization of Bayesian statistical inference, it has recently emerged as a candidate for next-generation AI toolchains.
>
> This course will convey both theoretical and practical aspects of using probabilistic AI to express complex probabilistic models as programs and understand the interplay of modeling and inference to efficiently solve real world problems:
>
> - Generative (Bayesian) Models
> - Conditioning and Posterior Sampling,
> - Programmable Inference for Probabilistic Programming Languages
> - Deep Probabilistic Programs (Bayesian Neural Networks),
> - Inference Methods: Markov Chain Monte Carlo (MCMC), Hamiltonian Monte Carlo, Variational Inference
> - Applications of Probabilistic Programming

#### Selbstorganisierende Systeme

| Name                         | Typ | ECTS | Stunden | Semester | ID      |
| ---------------------------- | --- | ---- | ------- | -------- | ------- |
| Selbstorganisierende Systeme | VU  | 4.5  | 3       | 2023W    | 188.413 |

[TISS ↗](https://tiss.tuwien.ac.at/course/courseDetails.xhtml?dswid=8621&dsrid=786&courseNr=188413&semester=2023W)

##### Lernergebnisse

> Nach positiver Absolvierung der Lehrveranstaltung sind Studierende in der Lage
>
> - Self-Organizing Maps zu trainieren
> - geeignete Visualisierungen für die SOM auszuwählen und zu kombinieren
> - anhand der vorliegenden Visualisierungen Muster in den Daten zu erkennen und Hypothesen zur Clusterstruktur zu erstellen
> - Strukturen zu interpretieren und kritisch zu hinterfragen
> - Die Funktionsweise von genetischen Algorithmen, Zellulären Automaten und Ant Colony Systemen zu verstehen, und deren Einsatzgebiete zu erkennen
> - Funktionsweise verschiedener Swarm Intelligence Systeme zu beschreiben und ahnhand ihrer Stärken und Schwächen Problemdomänen zu zuordnen
> - Particle Swarm Optimization Algorithm für eine bestimmte Optimierunsaufgabe zu implementieren und sein Parameter entsprechend zu tunen
> - Die grundlegende Methodik und Einsatzbereiche von Swarm Robotic aufzufassen und nachvollziehen

##### Inhalt der Lehrveranstaltung

> Unueberwachte und selbst-organisierende Lernverfahren, wie z.B. Self-Organizing Maps, Growing Hierarchical Structures, Zellulaere Automaten,
>
> Vortragstermine:
>
> - 12.10.: Vorbesprechung & erste Vorlesung
> - (weiterer Terminplan siehe TUWEL)
>   - TBA.: Genetic Algorithms, Cellular Automata, Swarms Grundlagen
>   - TBA.: Mutli-Agent Systems
>   - TBA.: Swarm Systems 1
>   - TBA.: Swarm Systems 2
>   - TBA.: SOM - Teil 1: Grundlagen, Architekturen, Trainingsmethoden
>   - TBA.: SOM - Teil 2: Visualisierung,
>   - TBA.: SOM - Teil 3: Visualisierung, Qualitätsmaße, verwandte Architekturen
>
> ECTS/Aufwand:
>
> Vorlesung: 8 Einheiten a 2h: 16h
>
> Literatur: 10h
>
> Übungsbeispiele:
>
>     Ex1: 20h
>
>     Ex2: 20h
>
>     Ex3: 20h
>
> Vorbereitung Prüfung: 25,5h
>
> Prüfung: 1h
>
> SUMME: 112.5h

#### Logik für Wissensrepräsentation

| Name                            | Typ | ECTS | Stunden | Semester | ID      |
| ------------------------------- | --- | ---- | ------- | -------- | ------- |
| Logik für Wissensrepräsentation | VU  | 6    | 4       | 2023W    | 192.025 |

[TISS ↗](https://tiss.tuwien.ac.at/course/courseDetails.xhtml?dswid=8621&dsrid=109&courseNr=192025&semester=2023W)

##### Lernergebnisse

> Nach positiver Absolvierung der Lehrveranstaltung sind Studierende in der Lage
>
> - unterschiedliche Logiken bzw. logikbasierte Formalismen zur Wissensrepräsentation zu benennen und zu erläutern,
> - Methoden und Techniken für eine vorgegebene Aufgabenstellung zielgerichtet auszuwählen, sowie
> - Lösungen und Formalismen kritisch zu bewerten.

##### Inhalt der Lehrveranstaltung

> Wissensrepräsentation ist ein Zweig der künstlichen Intelligenz welches zum Ziel hat, geeignete Methoden zu entwickeln um implizites Wissen über einen bestimmten Bereich so darzustellen, daß es von Computern verarbeitet werden kann. Das Gebiet der Wissensrepräsentation beinhaltet Techniken aus unterschiedlichen Disziplininen, im speziellen aus der Logik und der Ontologie.
>
> In dieser VO werden wir uns mit unterschiedlichen Logiken zur Wissensrepräsentation beschäftigen.
>
> Inhalt:
>
> 1. Einleitung
>    1. Überblick
>    2. Logik
> 2. Wissensrepräsentation mittels klassischer Logik
>    1. Elemente der Aussagenlogik
>    2. Aussagenlogik zur Modellierung von Schließen in der Umgangssprache
>    3. Elemente der Prädikatenlogik
>    4. Prädikatenlogik und Umgangssprache
>    5. Ontologische Aspekte
> 3. Nichtmonotones Schließen
>    1. Probleme klassischer Logik
>    2. Methoden nichtmonotonen Schließens
>    3. Circumscription
>    4. Default Logik
> 4. Parakonsistentes Schließen
> 5. Modallogik
>    - Einführung
>    - Syntax und Semantik
>    - Elementare Modallogiken

#### Einführung in Machine Learning

| Name                           | Typ | ECTS | Stunden | Semester | ID      |
| ------------------------------ | --- | ---- | ------- | -------- | ------- |
| Einführung in Machine Learning | VU  | 6    | 4       | 2023W    | 194.025 |

[TISS ↗](https://tiss.tuwien.ac.at/course/courseDetails.xhtml?dswid=8621&dsrid=838&courseNr=194025&semester=2023W)

##### Lernergebnisse

> Nach positiver Absolvierung der Lehrveranstaltung sind Studierende in der Lage grundlegende Konzepte des Maschinellen Lernens (inkl. Datenaufbereitung, Wahl von passenden Algorithmen, Evaluierung) beschreiben und diese entsprechend auf reale Problemstellungen anwenden.
>
> _Fachliche und methodische Kompetenzen_: Nach positiver Absolvierung des Moduls können die Studierenden
>
> - eine geeignete Strategie für das Bewältigen einer gegebenen Problemstellung erarbeiten (Auswahl von Algorithmen und Methoden),
> - Grundlagen und formale Konzepte des Maschinellen Lernens erarbeiten und anwenden,
> - eine geeignete Strategie für das Aufbereiten von realen Daten entwickeln,
> - ein Evaluierungskonzept definieren.
>
> _Kognitive und praktische Kompetenzen_: Nach positiver Absolvierung des Moduls können die Studierenden
>
> - bestehende Problemstellungen und deren zugrundeliegenden Konzepte verstehen,
> - Datenmengen analysieren und für deren korrekte Verwendung aufbereiten,
> - verschiedene Algorithmen und Lösungsansätze auf reale Daten anwenden,
> - angewandte Methoden korrekt evaluieren und Ergebnisse interpretieren.
>
> Soziale Kompetenzen und Selbstkompetenzen: Nach positiver Absolvierung des Moduls können Studierende Problemstellungen selbstständig analysieren, geeignete Methoden anwenden und evaluieren sowie Ergebnisse interpretieren.

##### Inhalt der Lehrveranstaltung

> Geplante Lehrinhalte sind:
>
> - Einführung, Geschichte und Taxonomie
> - Grundlegende Konzepte des Maschinellen Lernens (Fehlerschranken, Datenaufbereitung und Evaluierungsmethoden) und Applikationen
> - Regelbasierte Klassifikation und Regression
> - Clustering und Dimensionsreduktion
> - Lerntheorie
> - Kernmethoden
> - Probabilistische Modelle
> - Ensemble Methoden
> - Deep Learning
> - Online, Active und Reinforcement Learning
> - Ausblick inklusive Fairness und Ethik im Maschinellen Lernen

#### Sicherheit, Privacy und Erklärbarkeit in Maschinellem Lernen

| Name                                                         | Typ | ECTS | Stunden | Semester | ID      |
| ------------------------------------------------------------ | --- | ---- | ------- | -------- | ------- |
| Sicherheit, Privacy und Erklärbarkeit in Maschinellem Lernen | VU  | 3    | 2       | 2024S    | 194.055 |

[TISS ↗](https://tiss.tuwien.ac.at/course/courseDetails.xhtml?dswid=8621&dsrid=312&courseNr=194055)

##### Lernergebnisse

> Nach positiver Absolvierung der Lehrveranstaltung sind Studierende in der Lage...
>
> - Identify threats to privacy of individuals in machine learning datasets
> - Select fitting solutions for privacy-preserving machine learning
> - Understand attack vectors on machine learning models, and how attacls can be detected and mitigated
> - Select fitting concepts for explainable and interpretable machine learning

##### Inhalt der Lehrveranstaltung

- Techniken zur Wahrung der Privatsphäre, um sensible Informationen in den Eingabedaten zu anonymisieren, z.B. um den Datenaustausch zu erleichtern, mit besonderem Schwerpunkt auf den Auswirkungen auf den Nutzen der Daten und der darauf trainierten Modelle. Dazu gehören z.B. die k-Anonymity und verwandte Modelle wie l-Diversity sowie Differential Privacy etc.
- Generierung von synthetischen Daten
- Techniken zur Wahrung der Privatsphäre, wie z.B. Differential Privacy, um Informationslecks an trainierten Modellen zu verhindern.
- Angriffsvektoren auf Modelle des maschinellen Lernens, z.B. membership attacks und Model Stealing, Adversary Input Generation, und wie man sie einschränkt.
- Backdoor-Einbettung, um das Verhalten von scheinbar gutartigen Modellen für böswillige Zwecke zu manipulieren.
- Vertraulichkeitserhaltende Berechnung von Modellen des maschinellen Lernens, z.B. mit secure multi-party computation, und homomorphen Verschlüsselungsansätzen.
- Erklärbarkeit von Modellen des maschinellen Lernens, um ein besseres Verständnis und Vertrauen in die Modelle zu ermöglichen, z.B. durch Visualisierung, Regelextraktion, Zero-Shot Learning.

#### Project in Computer Science 1 - Machine Learning Algorithms and Applications

| Name                                                                         | Typ | ECTS | Stunden | Semester | ID      |
| ---------------------------------------------------------------------------- | --- | ---- | ------- | -------- | ------- |
| Project in Computer Science 1 - Machine Learning Algorithms and Applications | PR  | 6    | 4       | 2023W    | 194.119 |

[TISS ↗](https://tiss.tuwien.ac.at/course/courseDetails.xhtml?dswid=8621&dsrid=316&courseNr=194119&semester=2023W)

##### Lernergebnisse

> Nach positiver Absolvierung der Lehrveranstaltung sind Studierende in der Lage...
>
> - Forschungsarbeiten selbstständig zusammenzufassen,
> - für das (Nach-)Implementieren von Lernalgorithmen benötigte Informationen herzuleiten,
> - Implementierungen von Lernalgorithmen zu entwickeln,
> - diese auf Datensätze anzuwenden,
> - maschinellen Lernalgorithmen experimentell zu evaluieren,
> - verschiedene Algorithmen zu vergleichen um deren Schwächen und Stärken zu analysieren, und
> - geeignete Hyperparameter für die Algorithmen zu bestimmen
>
> ...falls sich diese für ein angewandtes Projekt entscheiden.
>
> Nach positiver Absolvierung der Lehrveranstaltung sind Studierende in der Lage...
>
> - theoretische Eigenschaften eines Lernalgorithmus zusammenzufassen und zu präsentieren,
> - theoretische Schwachpunkte eines Lernalgorithmus zu identifizieren,
> - selbstständig an spezifischen theoretischen Problemen zu arbeiten und diese zu lösen,
> - theoretische Ergebnisse anzuwenden, und
> - Annahmen der Algorithmen zu überprüfen

> ...falls sich diese für ein theoretisches Projekt entscheiden.

##### Inhalt der Lehrveranstaltung

> **Studierende können zwischen einem theoretischen und einem angewandten Projekt wählen (oder eine Kombination).**
>
> Projektvorschläge können auf unserer Homepage gefunden werden. Wir freuen uns auch über eigene kreative und konkrete Projektideen (Anforderungen stehen auf der Homepage).
>
> Das Ziel des **angewandten** Projekts ist es, sich selbstständig in Lernalgorithmen einzuarbeiten, diese (nach-) zu implementieren und anzuwenden. Es soll mit verschiedenen Algorithmen, Hyperparametern, Datensätzen, und/oder Anwendungen experimentiert werden. Beispiele hierfür sind:
>
> - Vergleich verschiedener Algorithmen,
> - Design von Benchmarks, oder
> - Anwendung der Algorithmen in (kreativen) Use Cases.
>
> Das Ziel des **theoretischen** Projekts ist es, an konkreten theoretischen Fragestellungen im Bereich des maschinellen Lernens zu arbeiten. Beispiele hierfür sind:
>
> - Formale Garantien für bestimmte Lernalgorithmen (wie Sample, Query oder Computational Complexity Schranken),
> - Worst-case Instanzen auf denen die untersuchten Algorithmen beweisbar schlecht sind, oder
> - Formalisierung der zugrundeliegenden Annahmen der Algorithmen.

#### Deep Learning for Natural Language Processing

| Name                                          | Typ | ECTS | Stunden | Semester | ID      |
| --------------------------------------------- | --- | ---- | ------- | -------- | ------- |
| Deep Learning for Natural Language Processing | VU  | 6    | 4       | 2024S    | 192.039 |

[TISS ↗](https://tiss.tuwien.ac.at/course/educationDetails.xhtml?dswid=8621&dsrid=906&courseNr=192039&semester=2024S)

##### Lernergebnisse

> Nach positiver Absolvierung der Lehrveranstaltung sind Studierende in der Lage unter Verwendung des PyTorch-Frameworks eigene neuronale Netzwerkmodelle für die Verarbeitung natürlicher Sprache zu entwerfen, zu implementieren und zu verstehen.

##### Inhalt der Lehrveranstaltung

> Welcome to this course on deep learning for natural language processing (NLP)! This course is designed to unravel the complexities of NLP through the lens of deep learning techniques. From fundamental concepts to advanced neural network architectures, we will explore the intricacies of how deep learning models can comprehend, generate, and manipulate human language. Get ready to embark on a transformative learning journey, where theory meets hands-on applications.
>
> The topics covered in the course include the following:
>
> - word vectors, word window classification, language models
> - backpropagation and neural networks, dependency parsing
> - PyTorch
> - recurrent neural networks and language models
> - seq2seq, machine translation, subword models
> - self-attention and transformers
> - pretraining, natural language generation
> - Hugging Face transformers
> - prompting, reinforcement learning from human feedback
> - question answering
> - convolutional neural networks, tree recursive neural networks and constituency parsing
> - insights between NLP and linguistics
> - code generation
> - training large language models
> - multimodal deep learning
> - co-reference resolution
> - interpretability and explainability

#### Seminar in Artificial Intelligence : Neuroscience-based Artificial Intelligence

| Name                                                                            | Typ | ECTS | Stunden | Semester | ID      |
| ------------------------------------------------------------------------------- | --- | ---- | ------- | -------- | ------- |
| Seminar in Artificial Intelligence : Neuroscience-based Artificial Intelligence | SE  | 3    | 2       | 2024S    | 192.037 |

[TISS ↗](https://tiss.tuwien.ac.at/course/courseDetails.xhtml?dswid=8621&dsrid=980&courseNr=192037)

##### Lernergebnisse

> Nach positiver Absolvierung der Lehrveranstaltung sind Studierende in der Lage
>
> - to name relevant aspects about neuroscience-based AI,
> - to describe the current research for a chosen topic from the area of neuroscience-based AI, and
> - to find relevant literature for a topic from research about neuroscience-based AI.
>
> At the end of the course, the students will be able to read and critique scientific papers. They will be able to analyse the methods proposed in the field of neuroscience-based AI, and evaluate their strengths and weaknesses. They will be able to prepare an oral presentation of their findings and discuss the studied methods in detail. Finally, they will be able to assess their peers’ work.

##### Inhalt der Lehrveranstaltung

> The seminar will cover topics belonging to a relevant subfield of machine learning and artificial intelligence (AI): neuroscience-inspired AI.
>
> The course will explore the intersection of computational neuroscience and machine learning, examining how they can help advance AI. Computational neuroscience uses mathematical models of the brain to understand the principles that govern neural systems. Combined with machine learning, it enables the development of algorithms that can model neural processing, offering insights into both neuroscience and AI. Typical problems include decoding the computation behind neural activity or deriving learning mechanisms that are biologically plausible. Key areas of focus for this seminar include:
>
> - **Biologically plausible learning methods**: Explore alternatives to backpropagation like predictive coding, Hebbian learning, and spike-timing-dependent plasticity.
> - **Bridging the gap between machine learning and neuroscience**: Learn about the fundamental differences between artificial neural networks and biological neural networks as well as the similarities.
> - **Computational models for brain function**: Examine models that decode how the brain processes information, stores memories, and makes decisions.

#### Knowledge Graphs

| Name             | Typ | ECTS | Stunden | Semester | ID      |
| ---------------- | --- | ---- | ------- | -------- | ------- |
| Knowledge Graphs | VU  | 3    | 2       | 2024S    | 192.116 |

[TISS ↗](https://tiss.tuwien.ac.at/course/educationDetails.xhtml?dswid=8621&dsrid=899&courseNr=192116&semester=2024S)

##### Lernergebnisse

> Nach positiver Absolvierung der Lehrveranstaltung sind Studierende in der Lage ein tiefes Verständnis von Knowledge Graphs zu demonstrieren (mehr Details weiter unten)! Zuerst die wichtigsten Daten, um die Beschreibung nicht zu verfälschen, in englischer Sprache:
>
> **Welcome to Knowledge Graphs 2024!**
>
> This semester, we are again going to offer a "best of both worlds" edition between virtual and physical participation:
>
> You are going to be able to partcipiate fully virtually if you like - no presence needed. Watch the videos whenever you like.
>
> We will offer four face-to-face live units (completely optional).

> **Live Units**
>
> You can find the dates and times in the corresponding TISS section. If you are blocked for some of them, no problem, they are optional. Some further facts:
>
> - Each live unit is just 2 hours, so the total time investment in the live units is 8 hours.
> - These are especially for those of you who like physical presence, and see this as motivating - we encourage you to participate in them, as it is always nice to meet face-to-face to stay motivated.
> - These will complement the virtual parts - we will go through some of the core points, see examples that hopefully motivate you, and can answer questions.
>
> The theme of them will be:
>
> - Live 1 - "Kick-Off Meeting" / Vorbesprechung
> - Live 2 - "Groundbreaking Knowledge Graph Projects - Get your final ideas for your one pagers"
> - Live 3 - "Let's Talk About AI Techniques"
> - Live 4 - "Bringing It All Together"
>
> **More**
>
> All other details will follow via TUWEL and/or in the first live unit (if you participate).
>
> If you want to join the course, please do not forget to register via TISS, so that you get all updates and will be able to access TUWEL when the course launches in 2024S!
>
> For those of you who join us, see you all soon!
>
> **A short "clickable" description can be found on the website:**
>
> [https://kg.dbai.tuwien.ac.at/kg-course/](https://kg.dbai.tuwien.ac.at/kg-course/)
>
> In TISS all details are presented linearly on one page.
>
> Die Lernergebnisse sind in drei Blöcke geteilt und wird, um die Beschreibung nicht zu verfälschen, in englischer Sprache vorgestellt:
>
> - Representations of Knowledge Graphs
>   (logic- and ML-based)
> - Systems for Knowledge Graphs
>   (scalablility and reasoning)
> - Applications of Knowledge Graphs
>   (real-world enterprise AI)
>
> An overarching aim of the course is to understand the connections between Knowledge Graphs (KGs), Artificial Intelligence (AI), Machine Learning (ML), Deep Learning and Data Science.
>
> Learning outcomes (LOs) are structured into exactly these three blocks. A particular focus is of gaining a broad understanding of all of the following learning outcomes, coming from throughout the database, semantic web, machine learning and data science communities.
>
> Representations
>
> The aim in this part is to understand and apply the predominant representations of knowledge and data in Knowledge Graphs.
>
> - (LO1) Understand and apply Knowledge Graph Embeddings
> - (LO2) Understand and apply logical knowledge in KGs
> - (LO3) Understand and apply Graph Neural Networks
> - (LO4) Compare different Knowledge Graph data models from the database, semantic web, machine learning and data science communities.
>
> ![Knowledge Graph Representations](https://kg.dbai.tuwien.ac.at/kg-course/tiss/kg-2-representations.png)
>
> This, crucially, includes the connections between using these types of knowledge in one Knowledge Graph.
>
> Systems
>
> The aim in this part is to be able to design and apply systems that manage Knowledge Graphs.
>
> - (LO5) Design and implement architectures of a Knowledge Graph
> - (LO6) Describe and apply scalable reasoning methods in Knowledge Graphs
> - (LO7) Apply a system to create a Knowledge Graph
> - (LO8) Apply a system to evolve a Knowledge Graph
>
> ![Knowledge Graph Systems](https://kg.dbai.tuwien.ac.at/kg-course/tiss/kg-3-systems.png)
>
> The latter two learning outcomes (together with LO11) provide a typical life-cycle of Knowledge Graphs: getting data into a KG, i.e., creating it (LO6), evolving a KG into a new one (LO7) and getting data out of a KG by providing services based on it (L11). Note that the term “life-cycle” is used loosely here, as in many Knowledge Graphs, providing applications is not necessarily the end of the life-cycle, but part of an on-going activity.
>
> ![Knowledge Graph Lifecycle](https://kg.dbai.tuwien.ac.at/kg-course/tiss/kg-4-lifecycle.png)
>
> Applications
>
> The aim of this part is to understand and design applications of Knowledge Graphs.
>
> - (LO9) Describe and design real-world applications of Knowledge Graphs
> - (LO10) Describe financial Knowledge Graph applications
> - (LO11) Apply a system to provide services through a Knowledge Graph
> - (LO12) Describe the connections between Knowledge Graphs (KGs), Machine Learning (ML) and Artificial Intelligence (AI)
>
> ![Knowledge Graph Applications](https://kg.dbai.tuwien.ac.at/kg-course/tiss/kg-5-applications.png)
>
> A particular focus here is getting a holistic understanding of the topics including their connections.

##### Inhalt der Lehrveranstaltung

> The course content is aligned to the learning outcomes (following the seminal didactical principle of constructive alignment). We here repeat them here and give details what material is covered in each.
>
> **Representations**
>
> - (LO1) Understand and apply Knowledge Graph Embeddings  
>   Knowledge Graph Embeddings (KGEs) are a large field of representations and techniques focused on a shared principle: how to represent of symbolic knowledge - as in typical databases or datasets (in our case, graphs) - in a sub-symbolic way - as in typical machine learning or deep learning scenarios (in our case, as vectors). We will cover the principles as well as selected seminal and recent KGE models such as the translation-based TransE, the semantic matching-based ComplEx, and the neural network-based ConvE.
> - (LO2) Understand and apply logical knowledge  
>   Logical knowledge representation is a broad traditional field of AI techniques rooted across many communities, including of course the knowledge representation and reasoning, databases, semantic web and other communities. As this aspect is covered in many courses, we will focus on (1) giving a short introduction, (2) show connections between the slightly different frameworks used by different communities and (3) focus on an aspect particularly relevant for Knowledge Graphs: how to represent logical knowledge that uses (i) full recursion - as needed by graph processing - and (ii) powerful object creation (existential quantification in logic terms) – as needed to discover unknown parts of a Knowledge Graph.
> - (LO3) Understand and apply Graph Neural Networks  
>   Graph Neural Networks (GNNs) are a rapidly-growing field - successfully applied in many applications – based on a very clear idea: can the structure of the graph (i.e., the symbolic world) be used as the structure of an artificial neural network (ANN) as in typical machine learning and deep learning scenarios. We will cover the principles as well as selected models. The goal is to understand how machine learning and deep learning models based on neural networks can be guided by graph data and knowledge.
> - (LO4) Compare different Knowledge Graph data models from the database, semantic web, machine learning and data science communities.  
>    KGEs, logical models and GNNs are ways of representing different forms of knowledge in a Knowledge Graph, and thus naturally need to talk about different data models that they are based on. In this part, we will dig deeper into different concrete data models of representing graphs and Knowledge Graphs. One particular focus will be temporal models for Knowledge Graphs. We will give brief overviews of data models from the database, Semantic Web and other communities, and will give pointers to courses that give more details on each of them.
>
> **Systems**
>
> - (LO5) Design and implement architectures of a Knowledge Graph  
>   Designing an IT architecture for any complex AI applications is a challenge, typically requiring to integrate a number of technologies. In this part, we will consider different technology stacks available for Knowledge Graphs, and how to decide which capabilities should be handled by which parts of the architecture. This includes topics such as storing large Knowledge Graphs, and the border between what the Knowledge Graph should handle and what external application code should handle. As a main example, we are going to use the Vadalog system and architecture developed at the University of Oxford together with TU Wien, the Central Bank of Italy and many others. For technology stacks covered in detail by other courses, we will stay high level here and give pointers.
> - (LO6) Describe and apply scalable reasoning methods in Knowledge Graphs  
>   While storing Knowledge Graphs is an important endeavour in itself, using it to derive new data, insights or other output, is a central service offered by a Knowledge Graph. Typically, for simple questions this is called querying, and for more complex questions and if it requires background knowledge, reasoning. Reasoning is a broad area, and in this part, we will focus on the representations and models most important for Knowledge Graphs: reasoning with KG Embeddings, logical knowledge that allows both full recursion as well as object creation, as well as Graph Neural Networks. We will also consider what it means to reason by combining these aspects.
> - (LO7) Apply a system to create a Knowledge Graph  
>   In this part, we are going to look at the first part of the Knowledge Graph lifecycle, namely creation. We will give a broad overview of available techniques with some pointers for further information. For Knowledge Graphs this topic includes schema mapping – with many classical techniques stemming from the database community on data exchange and integration, and record linkage, which typically includes an ensemble of Machine Learning methods. These topics will be covered as far as needed for giving a full picture of the KG lifecycle, and connections to other courses will be highlighted.
> - (LO8) Apply a system to evolve a Knowledge Graph  
>    Evolving a Knowledge Graph is a broad topic, and we are going to cover a representative selection of techniques here. In general, it can be divided into two areas: (i) Knowledge Graph completion (i.e., adding to it). We will here discuss link prediction as a central method, in particular including KG Embeddings as well as logic based reasoning with full recursion and existential quantification. We are also going to discuss how to add knowledge to a KG through techniques such as rule learning or model induction. (ii) Knowledge Graph cleaning (i.e. removing parts of a KG) which can either effect the data or knowledge stored in a KG. This is of course broader, and can include topics such as schema evolution, view maintenance, etc. We will provide a broad picture and pointers for further topics covered in other courses.
>
> **Applications**
>
> - (LO9) Describe and design real-world applications of Knowledge Graphs  
>   Systems and representations are central to this course, but hardly motivated without applications. We will give a broad coverage of real-world applications in many sectors, including: the finance sector, energy sector, logistics and supply chain sector, manufacturing sector, aerospace sector and many others. Our goal is to explore the actual real-world applications of Knowledge Graphs, and learn from them which parts of the broad field of KG techniques are used where, and how to use this for designing such data science and computer science applications ourselves.
> - (LO10) Describe financial Knowledge Graph applications  
>   We are going to dive deep into financial Knowledge Graph applications, which includes the banking sector (commercial banks), the central banking sector (i.e., national banks) and the insurance sector. All of these have connections but also different requirements that show-off particular properties of KGs quite well: while for a commercial bank a KG may be used for predicting customer needs, or in the insurance sector to ascertain credit worthiness, in a central bank the knowledge in a KG often is related to laws and regulations that need to be upheld (and checked by) central banks to protect financial systems. A typical uses case is for example helping to protect companies from hostile takeovers during crises, which we will take a deep dive into the respective real-world Knowledge Graph.
> - (LO11) Apply a system to provide services through a Knowledge Graph  
>   As a final step of creating and then involving a KG, we here give a glimpse into the finale step, namely services that can be provided through Knowledge Graphs. This will necessarily be just an overview, as many AI-based services today use one or more Knowledge Graphs. The typical services that information systems in general provide are in terms of general-purpose or broad analytics provided to a user, or in terms of specific queries or questions asked to a system. While we are point to a specific courses here for more details, we will give a broad overview of how to build structured query interfaces for KG queries and analytics, visualize Knowledge Graphs, build natural language query interfaces for complex KG queries and questions, and build KG-based recommender systems that use deep logic and KGE-based knowledge. In all of these, we will focus on the KG aspects, seeing how in particular a KG is used to support these services. Our goal is here not to understand visualization, recommender systems, etc. – there are specific courses for that – but to understand how an architecture that includes KGs works, and how KGs specifically help these services.
> - (LO12) Describe the connections between Knowledge Graphs (KGs), Machine Learning (ML) and Artificial Intelligence (AI)  
>   It is clear that Knowledge Graphs are an area of Artificial Intelligence where a number of techniques come together, and where new Machine Learning techniques such as KG Embeddings native to KGs have emergence. Arguably, it is one of the strengths of KG-based systems to allow all such techniques to come together in a well-organized architecture (some call it a “melting pot”). Yet, is all of KGs Artificial Intelligence? What about database systems and highly-scalable data processing techniques? A particularly interesting angle here are the reasoning techniques: How are traditional logic-based reasoning techniques coming together with Machine Learning-based ones? What is the connection to Neural Network-based methods, in particular those where the KG plays a central role (such as in GNNs)? These are questions we will openly consider in this part to allow everyone to not only understand the individual techniques, but how they connect to each other in KGs.
